{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= ['this glass of milk',\n",
    "            'this milk glass is hot',\n",
    "            'the fruit was not good',\n",
    "            'He played excellent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90, 5, 91, 3], [90, 3, 5, 54, 39], [24, 30, 58, 19, 82], [53, 8, 66]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_repr = [one_hot(word,100) for word in sentences]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass this to embeddding layer to form matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 4, 3], [1, 3, 2, 5, 6], [7, 8, 9, 10, 11], [12, 13, 14]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer(num_words=1000)\n",
    "token.fit_on_texts(sentences)\n",
    "token.word_index\n",
    "\n",
    "token.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(one_hot_repr,maxlen=5,padding = 'pre', truncating ='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 90,  5, 91,  3],\n",
       "       [90,  3,  5, 54, 39],\n",
       "       [24, 30, 58, 19, 82],\n",
       "       [ 0,  0, 53,  8, 66]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(100,10,input_length  =5))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00936234,  0.0361846 , -0.0392635 , -0.00846322,\n",
       "          0.01530493,  0.02636017,  0.0167301 , -0.02215564,\n",
       "          0.04939797, -0.01181148],\n",
       "        [ 0.02700721,  0.01277884,  0.01312052, -0.02601175,\n",
       "          0.04743867,  0.01997745,  0.00320622,  0.02168803,\n",
       "         -0.01976942,  0.01323234],\n",
       "        [ 0.00379182,  0.00060342,  0.0425001 , -0.01284522,\n",
       "          0.03159039,  0.03298551,  0.01554097,  0.02418892,\n",
       "          0.03036426,  0.04225177],\n",
       "        [-0.02478694, -0.0340395 , -0.0097519 ,  0.03022095,\n",
       "         -0.03805669, -0.03713442,  0.00328612, -0.03357768,\n",
       "         -0.0234124 , -0.00320087],\n",
       "        [-0.04386116,  0.0465299 ,  0.00624312,  0.01183497,\n",
       "         -0.02848735, -0.01378923, -0.0136701 , -0.0007839 ,\n",
       "          0.02696785, -0.00145662]],\n",
       "\n",
       "       [[ 0.02700721,  0.01277884,  0.01312052, -0.02601175,\n",
       "          0.04743867,  0.01997745,  0.00320622,  0.02168803,\n",
       "         -0.01976942,  0.01323234],\n",
       "        [-0.04386116,  0.0465299 ,  0.00624312,  0.01183497,\n",
       "         -0.02848735, -0.01378923, -0.0136701 , -0.0007839 ,\n",
       "          0.02696785, -0.00145662],\n",
       "        [ 0.00379182,  0.00060342,  0.0425001 , -0.01284522,\n",
       "          0.03159039,  0.03298551,  0.01554097,  0.02418892,\n",
       "          0.03036426,  0.04225177],\n",
       "        [-0.0289431 , -0.01112666,  0.00488033,  0.02460952,\n",
       "          0.01203961, -0.02179033, -0.02895433, -0.00468056,\n",
       "         -0.0188867 ,  0.02924706],\n",
       "        [-0.01709473,  0.04659755,  0.01288505, -0.00655608,\n",
       "          0.0093805 ,  0.04546226,  0.00011967,  0.03966972,\n",
       "         -0.00594627,  0.04139805]],\n",
       "\n",
       "       [[-0.04109138,  0.00398008,  0.04244481, -0.00305662,\n",
       "          0.02162136,  0.01357147, -0.03263245,  0.04356908,\n",
       "         -0.02081014,  0.0309369 ],\n",
       "        [-0.03169078, -0.02843311, -0.02662089,  0.03469488,\n",
       "          0.03870963, -0.02425296, -0.0015278 , -0.02113925,\n",
       "         -0.04769257,  0.0062061 ],\n",
       "        [-0.01069082, -0.04824971,  0.02588305, -0.03321461,\n",
       "          0.00742718, -0.01473324,  0.03528208, -0.04039676,\n",
       "         -0.04465485, -0.01464229],\n",
       "        [ 0.01337007,  0.00319215, -0.02805315,  0.04171633,\n",
       "          0.02224204, -0.00605149, -0.02589061,  0.01978859,\n",
       "         -0.01232881,  0.01645304],\n",
       "        [ 0.00859854,  0.0216094 ,  0.00916954, -0.02033544,\n",
       "          0.00590453, -0.01460076, -0.04114471, -0.03708883,\n",
       "          0.03202143, -0.01686209]],\n",
       "\n",
       "       [[ 0.00936234,  0.0361846 , -0.0392635 , -0.00846322,\n",
       "          0.01530493,  0.02636017,  0.0167301 , -0.02215564,\n",
       "          0.04939797, -0.01181148],\n",
       "        [ 0.00936234,  0.0361846 , -0.0392635 , -0.00846322,\n",
       "          0.01530493,  0.02636017,  0.0167301 , -0.02215564,\n",
       "          0.04939797, -0.01181148],\n",
       "        [ 0.04849371,  0.03263971,  0.00844429, -0.01380881,\n",
       "          0.00731497, -0.03749425,  0.03949592, -0.01732775,\n",
       "         -0.00541228,  0.02437093],\n",
       "        [ 0.03355011, -0.03250275, -0.03592398,  0.02059635,\n",
       "          0.04556003,  0.0311872 , -0.00123717, -0.0307744 ,\n",
       "          0.04339596,  0.03542414],\n",
       "        [-0.04136623,  0.04372802, -0.00910642, -0.03672526,\n",
       "         -0.00366313,  0.02900947,  0.04868628, -0.0242513 ,\n",
       "          0.01387007, -0.02524687]]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 90,  5, 91,  3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00936234,  0.0361846 , -0.0392635 , -0.00846322,  0.01530493,\n",
       "         0.02636017,  0.0167301 , -0.02215564,  0.04939797, -0.01181148],\n",
       "       [ 0.02700721,  0.01277884,  0.01312052, -0.02601175,  0.04743867,\n",
       "         0.01997745,  0.00320622,  0.02168803, -0.01976942,  0.01323234],\n",
       "       [ 0.00379182,  0.00060342,  0.0425001 , -0.01284522,  0.03159039,\n",
       "         0.03298551,  0.01554097,  0.02418892,  0.03036426,  0.04225177],\n",
       "       [-0.02478694, -0.0340395 , -0.0097519 ,  0.03022095, -0.03805669,\n",
       "        -0.03713442,  0.00328612, -0.03357768, -0.0234124 , -0.00320087],\n",
       "       [-0.04386116,  0.0465299 ,  0.00624312,  0.01183497, -0.02848735,\n",
       "        -0.01378923, -0.0136701 , -0.0007839 ,  0.02696785, -0.00145662]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded)[0]\n",
    "\n",
    "There were 4 sentences each word has its own vector dimension  of 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
